{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepping Images for Training\n",
    "\n",
    "If you have the original images and want to preprocess them like I did, just run this notebook!\n",
    "\n",
    "- I saved some code that visualizes the masks/rectangles at the end of the notebook as Raw NBConvert.\n",
    "- If you want to visualize the bounding boxes/masks, just turn them back into code cells and run!\n",
    "\n",
    "In this notebook:\n",
    "\n",
    " - I resize the images to 50% of the original size and turn the images into greyscale and save them.\n",
    " - I slice the images and masks and save them.\n",
    " - I find the coordinates for the rectangles around the masks for each of the kidney images.\n",
    " - I create and save a dataframe containing the target cell info of the sliced images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import tifffile as tiff\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '../train/images/'\n",
    "images = os.listdir(img_path)\n",
    "\n",
    "mask_path = '../train/masks'\n",
    "\n",
    "test_path = '../test/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../CSVs/train.csv')\n",
    "img_name_list = df['id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2f6ecfcdf</td>\n",
       "      <td>296084587 4 296115835 6 296115859 14 296147109...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaa6a05cc</td>\n",
       "      <td>30989109 59 31007591 64 31026074 68 31044556 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cb2d976f4</td>\n",
       "      <td>78144363 5 78179297 15 78214231 25 78249165 35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0486052bb</td>\n",
       "      <td>101676003 6 101701785 8 101727568 9 101753351 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e79de561c</td>\n",
       "      <td>7464094 14 7480273 41 7496453 67 7512632 82 75...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           encoding\n",
       "0  2f6ecfcdf  296084587 4 296115835 6 296115859 14 296147109...\n",
       "1  aaa6a05cc  30989109 59 31007591 64 31026074 68 31044556 7...\n",
       "2  cb2d976f4  78144363 5 78179297 15 78214231 25 78249165 35...\n",
       "3  0486052bb  101676003 6 101701785 8 101727568 9 101753351 ...\n",
       "4  e79de561c  7464094 14 7480273 41 7496453 67 7512632 82 75..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make some folders for organization purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder for our grey images\n",
    "try:\n",
    "    os.mkdir('../train/images/grey')\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder for our slices\n",
    "try:\n",
    "    os.mkdir('../train/images/slices')\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder for our mask images\n",
    "try:\n",
    "    os.mkdir('../train/masks')\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder for our mask images\n",
    "try:\n",
    "    os.mkdir('../train/masks/slices')\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder for our test slices\n",
    "try:\n",
    "    os.mkdir('../test/images/slices')\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder for our test grey images\n",
    "try:\n",
    "    os.mkdir('../test/images/grey')\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The source for this function: \n",
    "# https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n",
    "# edited to suit my notebook\n",
    "\n",
    "def rle2mask(img_id):\n",
    "    '''\n",
    "    img_id: the id number of image\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (width,height) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    path = os.path.join(img_path, img_id+'.tiff')\n",
    "    image = tiff.imread(path)\n",
    "    mask_rle = df[df['id'] == img_id]['encoding'].values[0]\n",
    "    \n",
    "    if len(image.shape) == 5:\n",
    "            image = image.squeeze().transpose(1, 2, 0)\n",
    "    \n",
    "    shape=(image.shape[1],image.shape[0])\n",
    "    \n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    \n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes image id and scale percentage (eg: 0.5) \n",
    "# and returns the image resized by the scale percentage\n",
    "\n",
    "def resize_img(img_id, scale_percent):\n",
    "        path = os.path.join(img_path, img_id+'.tiff')\n",
    "        image = tiff.imread(path)\n",
    "        if len(image.shape) == 5:\n",
    "            image = image.squeeze().transpose(1, 2, 0)\n",
    "        \n",
    "        width = int(image.shape[1] * scale_percent)\n",
    "        height = int(image.shape[0] * scale_percent)\n",
    "        dimensions = (width, height)\n",
    "        \n",
    "        resized = cv2.resize(image, dimensions)\n",
    "        return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes mask id and scale percentage (eg: 0.5) \n",
    "# and returns the mask resized by the scale percentage\n",
    "\n",
    "def resize_masks(image_id, scale):\n",
    "    maskpath = os.path.join(mask_path, name + '_mask.tiff')\n",
    "    mask = tiff.imread(maskpath)\n",
    "    fullpath = os.path.join(img_path, name + '_small.tiff')\n",
    "    image = tiff.imread(fullpath)\n",
    "    \n",
    "    width = int(mask.shape[1] * scale)\n",
    "    height = int(mask.shape[0] * scale)\n",
    "    dimensions = (width, height)\n",
    "    resized = cv2.resize(mask, dimensions)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function turns images grey\n",
    "\n",
    "def to_grey(img_id):\n",
    "    path = os.path.join(img_path, img_id + '.tiff')\n",
    "    image = tiff.imread(path)\n",
    "    weights = [0.2989, 0.5870, 0.1140]\n",
    "    grey_img = np.dot(image, weights)\n",
    "    return grey_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://stackoverflow.com/questions/53755910/how-can-i-split-a-large-image-into-small-pieces-in-python\n",
    "\n",
    "def slice_grey(image_id):\n",
    "    fullpath = os.path.join(img_path + 'grey', image_id + '.tiff')\n",
    "    image = tiff.imread(fullpath)\n",
    "    real_id = image_id[:-11]\n",
    "    \n",
    "    for r in range(0, image.shape[0], int(image.shape[0]/32)):\n",
    "        for c in range(0, image.shape[1], int(image.shape[1]/32)):\n",
    "            cv2.imwrite(f\"../train/images/slices/{real_id}_{r}_{c}.tiff\", \n",
    "                        image[r:r+ int(image.shape[0]/32), c:c+ int(image.shape[1]/32)])\n",
    "        \n",
    "    print(f'{image_id} has been sliced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_masks(image_id):\n",
    "    path = os.path.join(mask_path, image_id + '.tiff')\n",
    "    image = tiff.imread(path)\n",
    "    real_id = image_id[:-11]\n",
    "    \n",
    "    for r in range(0, image.shape[0], int(image.shape[0]/32)):\n",
    "        for c in range(0, image.shape[1], int(image.shape[1]/32)):\n",
    "            cv2.imwrite(f\"../train/masks/slices/{real_id}_{r}_{c}.tiff\", \n",
    "                        image[r:r+ int(image.shape[0]/32), c:c+ int(image.shape[1]/32)])\n",
    "            \n",
    "    print(f'{image_id} has been sliced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take the RLE masks, turn it into an image, save the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2f6ecfcdf mask has been created\n",
      "aaa6a05cc mask has been created\n",
      "cb2d976f4 mask has been created\n",
      "0486052bb mask has been created\n",
      "e79de561c mask has been created\n",
      "095bf7a1f mask has been created\n",
      "54f2eec69 mask has been created\n",
      "1e2425f28 mask has been created\n"
     ]
    }
   ],
   "source": [
    "for names in img_name_list:\n",
    "    mask = rle2mask(names)\n",
    "    mask_img = Image.fromarray(mask*255)\n",
    "    fullpath = os.path.join(mask_path, names + '_mask.tiff')\n",
    "    mask_img.save(fullpath)\n",
    "    \n",
    "    print(f'{names} mask has been created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing the images for training:\n",
    "The original images were too big for my computer to train on, so I need to make them smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2f6ecfcdf resized has been created\n",
      "aaa6a05cc resized has been created\n",
      "cb2d976f4 resized has been created\n",
      "0486052bb resized has been created\n",
      "e79de561c resized has been created\n",
      "095bf7a1f resized has been created\n",
      "54f2eec69 resized has been created\n",
      "1e2425f28 resized has been created\n",
      "Wall time: 2min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for names in img_name_list:\n",
    "    smaller = resize_img(names, 0.5)\n",
    "    fullpath = os.path.join(img_path, names + '_small.tiff')\n",
    "    cv2.imwrite(fullpath,smaller)    \n",
    "    print(f'{names} resized has been created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize the mask images so that they fit the smaller images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2f6ecfcdf resized mask has been created\n",
      "aaa6a05cc resized mask has been created\n",
      "cb2d976f4 resized mask has been created\n",
      "0486052bb resized mask has been created\n",
      "e79de561c resized mask has been created\n",
      "095bf7a1f resized mask has been created\n",
      "54f2eec69 resized mask has been created\n",
      "1e2425f28 resized mask has been created\n",
      "Wall time: 55.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for name in img_name_list:\n",
    "    small = resize_masks(name, 0.5)\n",
    "    path = os.path.join('../train/masks', name + '_mask_small.tiff')\n",
    "    cv2.imwrite(path, small)\n",
    "    print(f'{name} resized mask has been created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make images greyscale to make them even smaller in filesize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2f6ecfcdf_small',\n",
       " 'aaa6a05cc_small',\n",
       " 'cb2d976f4_small',\n",
       " '0486052bb_small',\n",
       " 'e79de561c_small',\n",
       " '095bf7a1f_small',\n",
       " '54f2eec69_small',\n",
       " '1e2425f28_small']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_names = [i + '_small' for i in img_name_list]\n",
    "small_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2f6ecfcdf_small is grey now\n",
      "aaa6a05cc_small is grey now\n",
      "cb2d976f4_small is grey now\n",
      "0486052bb_small is grey now\n",
      "e79de561c_small is grey now\n",
      "095bf7a1f_small is grey now\n",
      "54f2eec69_small is grey now\n",
      "1e2425f28_small is grey now\n"
     ]
    }
   ],
   "source": [
    "for name in small_names:\n",
    "    grey = to_grey(name)\n",
    "    grey_path = os.path.join(img_path + 'grey', name +'_grey.tiff')\n",
    "    cv2.imwrite(grey_path, grey)    \n",
    "    \n",
    "    print(f'{name} is grey now')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split each image into smaller tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "grey_names = [i+'_small_grey' for i in img_name_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2f6ecfcdf_small_grey has been sliced\n",
      "aaa6a05cc_small_grey has been sliced\n",
      "cb2d976f4_small_grey has been sliced\n",
      "0486052bb_small_grey has been sliced\n",
      "e79de561c_small_grey has been sliced\n",
      "095bf7a1f_small_grey has been sliced\n",
      "54f2eec69_small_grey has been sliced\n",
      "1e2425f28_small_grey has been sliced\n"
     ]
    }
   ],
   "source": [
    "for name in grey_names:\n",
    "    slice_grey(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now I need to slice the masks into the same squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_name = [i+'_mask_small' for i in img_name_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2f6ecfcdf_mask_small has been sliced\n",
      "aaa6a05cc_mask_small has been sliced\n",
      "cb2d976f4_mask_small has been sliced\n",
      "0486052bb_mask_small has been sliced\n",
      "e79de561c_mask_small has been sliced\n",
      "095bf7a1f_mask_small has been sliced\n",
      "54f2eec69_mask_small has been sliced\n",
      "1e2425f28_mask_small has been sliced\n"
     ]
    }
   ],
   "source": [
    "for name in mask_name:\n",
    "    slice_masks(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not all slices are useful. I only want to keep the slices that contain masks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_slices = os.listdir('../train/masks/slices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "save_list = []\n",
    "delete_list =[]\n",
    "\n",
    "for name in mask_slices:\n",
    "    path = os.path.join('../train/masks/slices', name)\n",
    "    image = tiff.imread(path)\n",
    "    if 255 in image:\n",
    "        save_list.append(name)\n",
    "    else:\n",
    "        delete_list.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure there's no overlap between the two lists\n",
    "list(set(save_list) & set(delete_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# save: 1797\n",
      "# to be deleted: 6915\n"
     ]
    }
   ],
   "source": [
    "print(f'# save: {len(save_list)}\\n# to be deleted: {len(delete_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# delete unneccessary images in masks slices folder\n",
    "for name in delete_list:\n",
    "    path = os.path.join('../train/masks/slices', name)\n",
    "    if os.path.isfile(path): \n",
    "        os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# delete unneccessary images from the grey images slices folder\n",
    "for name in delete_list:\n",
    "    path = os.path.join('../train/images/slices', name)\n",
    "    if os.path.isfile(path): \n",
    "        os.remove(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each instance in the masks needs to be a different \"color\"\n",
    "Right now, they're all white. Need to make each instance different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_different(image):\n",
    "    path = os.path.join('../train/masks/slices', image)\n",
    "    img = tiff.imread(path)\n",
    "    contours = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = imutils.grab_contours(contours)\n",
    "    a = 1\n",
    "    for c in contours:\n",
    "        img = cv2.fillPoly(img, [c], color=(a,1,1))\n",
    "        image = Image.fromarray(img)\n",
    "        image.save(path)\n",
    "        a+=1\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_masks = os.listdir('../train/masks/slices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sliced_masks:\n",
    "    make_different(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize one of the masks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=503x418 at 0x1CA36A6D9A0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is what it looks like without a filter\n",
    "mask = tiff.imread('../train/masks/slices/1e2425f28_4598_3521.tiff')\n",
    "image = Image.fromarray(mask)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This filter will help us see the masks:\n",
    "\n",
    "image.putpalette([\n",
    "    0, 0, 0, # black background\n",
    "    255, 0, 0, # index 1 is red\n",
    "    255, 255, 0, # index 2 is yellow\n",
    "    255, 192, 203, # index 3 is pink\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAGiAgMAAACHWGfwAAAADFBMVEUAAAD/AAD//wD/wMsr0q8GAAAEU0lEQVR4nO3cS3KjQBAEUDscrFlxHjgCi+E+OoqWDp2ij9QHmAhm7PHY+kFXtbOqjMjcWZtnJdUthfg8PTEMwzAMwzAMwzAMwzAMwzAMwzAMwzAMwzAMwzAMwzB7zu9QvZ3nwH/gZX5LjuLnj8T8A/38meSvv8xn8R+B+SLeen/JJ1/95VL3Hr/5Oq56f8MnR7290V3bv9U9l95t9Z4H/071jgf/es05t3+3erf271fv1f5C9bPT0luq3ufgL1bvcvCXq3dpf023b3+tevv2V6ufsUvvcPtSQYce/OPNK32JR7b/ev1CqXps+6frF8o6lD9c/l2uHnrwT8eLPwXVW/IS3Y6XVG/Hi6q341sZD9z1L3hZ94/Ky3QrXjh5yE3/dLbpR/Bnm34by/ex5QfzUh34iXvGiyfPhm93zfexvFgHfuL+GF4++CZ8uxke94n7xfexvFyP5jOeVwy+Bd8q+ITn++3wMP2LV+gGvGbykN/zTz+Cb2P5XsHnh+MVOvSXrX+8ZvKieZz+n29j+X47PPJ8wgevefN4XjV5Gc63G+ITnO9jeY0OPZMVzb9921ENPp5vNTr0LOZP4HsNn6H88Uk5ecF8Ig/jD1oeqW+Ox147od7yg/lMHpZXLZ92zUP1aP6o5MFXbG2Mzw/FH5R8iuWx+sZ4kysl5XyO5dOueQtdzttcoyvm8675FMub6GLe6OrwjfA5lk+75m30gGs0a/i8az7F8ka6kDe7IWcTfLbiexGfYnkrXXg2I5a3uxNNxGczXnQiLT0qL1r4drqEt7wHsi/zedd8MuTbMm+oC3jTu2/LCz+Yz5Z8eeGnWN5UL6+8WN74tvMSn235tsCnh+ZLC99WL/HmDzwI5tcPfrbm19tP1vx6++b6+sZjz6+17/GclRU+O/Ar7ScHvo3lV9r30Jfb93m802L72YVfXHo+/GL7yYdfat9HX2o/O/H3l56bfrf95Kbfa99Rj36W4k37vvq1761f+CFPsW1D9U8/x+gffpj+7qc4/a8fqjMMwzAMwzAMw+whzRCIP0/TFOdP7wnyu2mK85+nr/xy15vpPKOzPl1l8MSba93Vv8Ud/Ttv3dFfwJ38pffu5K/xDn63xtv7q7q9X+CN/ecSb7v/NkXe1O/KvKUv4Q19iW7nlyfP1JfyRn4j5W38Tsyb+HLd5OungjfYfsWTZ9N+o+Hx7av4Cc53Kn5E8yod334srxr8CX7wGyU/PBTfKfkRyyt18OxpJy+ax45+o+YHJN9tjR+RvFqHzp5+8qJ55Og3FfyA47sKfsTxFTry4MfyNZMHnL1mi/yA4rtYvkrHrbw6HjX6dYMfzaNGv5YfyH8/DXnyu+Q78uTJ+/OVOnnyUfwI0Wu/6pEnT/4baWr5Ydc8RN8qD/pxJZjvKvlx1/ywax6jR/OVejCP+kmXfEVG8t/Pvn9O3yiP0XfON3U6atMjX5GRfBw/gPiOvD4gnXxFaje9Pwk6wVdGJGvhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=P size=503x418 at 0x1CA36A6D9A0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make new csv with the width, height, xmin, ymin, xmax, ymax from all the tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_list = os.listdir('../train/masks/slices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "contour_list_tiles = []\n",
    "\n",
    "for name in save_list:\n",
    "    path = os.path.join('../train/masks/slices', name)\n",
    "    image = tiff.imread(path)\n",
    "    \n",
    "    contours = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = imutils.grab_contours(contours)\n",
    "    \n",
    "    for c in contours:\n",
    "        contour_dict = {}\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        \n",
    "        contour_dict['filename'] = name\n",
    "        contour_dict['width'] = w\n",
    "        contour_dict['height'] = h\n",
    "        contour_dict['class'] = 'glomeruli'\n",
    "        contour_dict['xmin'] = x\n",
    "        contour_dict['ymin'] = y\n",
    "        contour_dict['xmax'] = x+w\n",
    "        contour_dict['ymax'] = y+h\n",
    "\n",
    "        contour_list_tiles.append(contour_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "glomeruli_tiles = pd.DataFrame(contour_list_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0486052bb_10050_3815.tiff</td>\n",
       "      <td>118</td>\n",
       "      <td>123</td>\n",
       "      <td>glomeruli</td>\n",
       "      <td>427</td>\n",
       "      <td>279</td>\n",
       "      <td>545</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0486052bb_10050_4360.tiff</td>\n",
       "      <td>92</td>\n",
       "      <td>125</td>\n",
       "      <td>glomeruli</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "      <td>92</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0486052bb_10050_4360.tiff</td>\n",
       "      <td>193</td>\n",
       "      <td>167</td>\n",
       "      <td>glomeruli</td>\n",
       "      <td>307</td>\n",
       "      <td>108</td>\n",
       "      <td>500</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0486052bb_10050_4905.tiff</td>\n",
       "      <td>106</td>\n",
       "      <td>79</td>\n",
       "      <td>glomeruli</td>\n",
       "      <td>117</td>\n",
       "      <td>218</td>\n",
       "      <td>223</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0486052bb_10050_4905.tiff</td>\n",
       "      <td>121</td>\n",
       "      <td>126</td>\n",
       "      <td>glomeruli</td>\n",
       "      <td>424</td>\n",
       "      <td>74</td>\n",
       "      <td>545</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    filename  width  height      class  xmin  ymin  xmax  ymax\n",
       "0  0486052bb_10050_3815.tiff    118     123  glomeruli   427   279   545   402\n",
       "1  0486052bb_10050_4360.tiff     92     125  glomeruli     0   277    92   402\n",
       "2  0486052bb_10050_4360.tiff    193     167  glomeruli   307   108   500   275\n",
       "3  0486052bb_10050_4905.tiff    106      79  glomeruli   117   218   223   297\n",
       "4  0486052bb_10050_4905.tiff    121     126  glomeruli   424    74   545   200"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glomeruli_tiles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "glomeruli_tiles.to_csv('../CSVs/glomeruli_tiles.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize the test images and make them grey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_test(img_id, scale_percent):\n",
    "        path = os.path.join('../test/images', img_id+'.tiff')\n",
    "        image = tiff.imread(path)\n",
    "        if len(image.shape) == 5:\n",
    "            image = image.squeeze().transpose(1, 2, 0)\n",
    "        \n",
    "        width = int(image.shape[1] * scale_percent)\n",
    "        height = int(image.shape[0] * scale_percent)\n",
    "        dimensions = (width, height)\n",
    "        \n",
    "        resized = cv2.resize(image, dimensions)\n",
    "        return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_grey_test(img_id):\n",
    "    path = os.path.join('../test/images', img_id + '.tiff')\n",
    "    image = tiff.imread(path)\n",
    "    weights = [0.2989, 0.5870, 0.1140]\n",
    "    grey_img = np.dot(image, weights)\n",
    "    return grey_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = os.listdir('../test/images')[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = [i[:-5] for i in test_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['26dc41664', 'afa5e8098', 'b2dc8411c', 'b9a3865fc', 'c68fe75ea']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26dc41664 has been resized\n",
      "afa5e8098 has been resized\n",
      "b2dc8411c has been resized\n",
      "b9a3865fc has been resized\n",
      "c68fe75ea has been resized\n"
     ]
    }
   ],
   "source": [
    "for name in test_ids:\n",
    "    smaller = resize_test(name, 0.5)\n",
    "    fullpath = os.path.join('../test/images', name+ '_small.tiff')\n",
    "    cv2.imwrite(fullpath, smaller)\n",
    "    print(f'{name} has been resized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_small = [i + '_small' for i in test_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26dc41664_small is grey now\n",
      "afa5e8098_small is grey now\n",
      "b2dc8411c_small is grey now\n",
      "b9a3865fc_small is grey now\n",
      "c68fe75ea_small is grey now\n"
     ]
    }
   ],
   "source": [
    "for name in test_small:\n",
    "    grey = to_grey_test(name)\n",
    "    fullpath = os.path.join('../test/images/grey', name+ '_grey.tiff')\n",
    "    cv2.imwrite(fullpath, grey)\n",
    "    print(f'{name} is grey now')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split each test image into smaller tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "grey_names = [i + '_grey' for i in test_small]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_test(image_id):\n",
    "    fullpath = os.path.join('../test/images/grey', image_id + '.tiff')\n",
    "    image = tiff.imread(fullpath)\n",
    "    real_id = image_id[:-11]\n",
    "    \n",
    "    if image.shape[0] < 15000:\n",
    "        for r in range(0, image.shape[0], int(image.shape[0]/16)):\n",
    "            for c in range(0, image.shape[1], int(image.shape[1]/16)):\n",
    "                cv2.imwrite(f\"../test/images/slices/{real_id}_{r}_{c}.tiff\", image[r:r+ int(image.shape[0]/16), c:c+ int(image.shape[1]/16)])\n",
    "        \n",
    "    else:\n",
    "        for r in range(0, image.shape[0], int(image.shape[0]/32)):\n",
    "            for c in range(0, image.shape[1], int(image.shape[1]/32)):\n",
    "                cv2.imwrite(f\"../test/images/slices/{real_id}_{r}_{c}.tiff\", image[r:r+ int(image.shape[0]/32), c:c+ int(image.shape[1]/32)])\n",
    "    print(f'{image_id} has been sliced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26dc41664_small_grey has been sliced\n",
      "afa5e8098_small_grey has been sliced\n",
      "b2dc8411c_small_grey has been sliced\n",
      "b9a3865fc_small_grey has been sliced\n",
      "c68fe75ea_small_grey has been sliced\n"
     ]
    }
   ],
   "source": [
    "for name in grey_names:\n",
    "    slice_test(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Everything is prepped now, time to model :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some extra code:  \n",
    "### Load in one of the new image masks, find contours, making bounding rectangle, and visualize the rectangles \n",
    "If you want to visualize the masks, turn the cells back into code cells and run"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "path = os.path.join(mask_path, '1e2425f28'+'_mask.tiff')\n",
    "image = tiff.imread(path)\n",
    "contours = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = imutils.grab_contours(contours)\n",
    "    \n",
    "for c in contours:\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    drawn = cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,0),1)\n",
    "\n",
    "    fullpath = os.path.join(mask_path, '1e2425f28' + '_contours.tiff')\n",
    "    cv2.imwrite(fullpath, drawn)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "path2 = os.path.join(mask_path, '1e2425f28'+'_contours.tiff')\n",
    "contoured_img = cv2.imread(path2)\n",
    "\n",
    "width = int(contoured_img.shape[1] * 0.5)\n",
    "height = int(contoured_img.shape[0] * 0.5)\n",
    "dimensions = (width, height)\n",
    "        \n",
    "small = cv2.resize(contoured_img, dimensions)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize=[20,20])\n",
    "zoomed = small[5000:5300, 5000:5850]\n",
    "plt.imshow(zoomed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the new image masks, find contours, make dictionary with width, height, xmin, ymin, xmax, ymax, put dictionary in list\n",
    "If you want a CSV of the masks of the originals, turn these cells back into code cells and run"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "contour_list = []\n",
    "\n",
    "for name in img_name_list:\n",
    "    path = os.path.join(mask_path, name +'_mask.tiff')\n",
    "    image = tiff.imread(path)\n",
    "    \n",
    "    contours = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = imutils.grab_contours(contours)\n",
    "    \n",
    "    for c in contours:\n",
    "        contour_dict = {}\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        \n",
    "        contour_dict['filename'] = name + '.tiff'\n",
    "        contour_dict['width'] = w\n",
    "        contour_dict['height'] = h\n",
    "        contour_dict['class'] = 'glomeruli'\n",
    "        contour_dict['xmin'] = x\n",
    "        contour_dict['ymin'] = y\n",
    "        contour_dict['xmax'] = x+w\n",
    "        contour_dict['ymax'] = y+h\n",
    "\n",
    "        contour_list.append(contour_dict)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "glomeruli = pd.DataFrame(contour_list)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "glomeruli.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "glomeruli.to_csv('../CSVs/glomeruli.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
